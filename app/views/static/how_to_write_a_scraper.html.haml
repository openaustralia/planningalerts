- content_for :page_title, "How to write a scraper"
%h3= yield :page_title

%h4 What are scrapers?
%p
  To be able to display and send alerts for planning applications, PlanningAlerts needs to download applications from as many councils as possible. As the vast majority of councils don't supply the data in a reusable,
  machine-readable format we need to write
  = link_to "web scrapers", "https://secure.wikimedia.org/wikipedia/en/wiki/Web_scraping"
  for each local government authority.
%p
  These scrapers fetch the data from council web pages and present it in a structured format so we can load it into
  the PlanningAlerts database.

%h4 How can I help?
%p
  If you have some computer programming experience, you should be able to work out how to prepare a scraper for
  PlanningAlerts. By using our preferred scraping technology,
  #{link_to "ScraperWiki", "https://scraperwiki.com/"}, you can write a scraper using nothing but your web browser.
%p
  The next thing to do is to decide what council to scrape. Once you've picked one, look it up on
  our
  = link_to "crowd-sourced list of councils", "https://docs.google.com/spreadsheet/ccc?key=0AmvYMal8CGUsdG1tM0lEWUctR194eGN6bUh0VGFfc1E"
  and have a look at their published planning applications. Quickly double-check that the council isn't #{link_to "covered already", authorities_path}.

%h4 An introduction to scraping with ScraperWiki
%p
  Even if you've never done any scraping, you'll quickly get up and running with some straightforward tutorials available on the Scraperwiki site.
%p
  With ScraperWiki, you can choose to write your scraper in Ruby, Python or PHP so there's a good chance
  you're already familiar an available programming language.
%p
  Read tutorials on scraping with ScraperWiki for #{link_to "Ruby", "https://scraperwiki.com/docs/ruby/"},
  #{link_to "Python", "https://scraperwiki.com/docs/python/"} or #{link_to "PHP", "https://scraperwiki.com/docs/php/"}.

%h4 Now it's time to scrape
%p
  = link_to "Create your own ScraperWiki account", "https://scraperwiki.com/login/#signup"
  and
  = link_to "create a new scraper", "https://scraperwiki.com"
  that downloads and saves the following information:

%p The following fields are <span class="highlight">required</span>. All development applications should have these bits of information.
%table.scraper_fields
  %tbody
    %tr
      %th.field field
      %th.example Example value
      %th Description
    %tr
      %td.field council_reference
      %td.example TA/00323/2012
      %td
        %p
          The ID that the council has given the planning application. This also must be the unique key for this data
          set.
    %tr
      %td.field address
      %td.example 1 Sowerby St, Goulburn, NSW
      %td 
        %p
          The physical address that this application relates to. This will be geocoded so doesn't need to be a specific format but obviously the more explicit it is the more likely it will be successfully geo-coded. If the original address did not include the state (e.g. "QLD") at the end, then add it.
    %tr
      %td.field description
      %td.example Ground floor alterations to rear and first floor addition
      %td 
        %p
          A text description of what the planning application seeks to carry out.
    %tr
      %td.field info_url
      %td.example http://foo.gov.au/app?key=527230
      %td
        %p
          A URL that provides more information about the planning application.
        %p
          This should be a persistent URL that preferably is specific to this particular application. In many cases councils force
          users to click through a license to access planning application. In this case be careful about what URL you provide. Test clicking the link in a browser that hasn't established a session with the council's site to ensure users of PlanningAlerts will be able to click the link and not be presented with an error.
    %tr
      %td.field comment_url
      %td.example http://foo.gov.au/comment?key=527230
      %td 
        %p
          A URL where users can provide a response to council about this particular application.
        %p
          As in info_url this needs to be a persistent URL and should be specific to this particular application if possible.
          Email mailto links are also valid in this field.
    %tr
      %td.field date_scraped
      %td.example 2012-08-01
      %td
        %p
          The date that your scraper is collecting this data (i.e. now). Should be in
          = link_to "ISO 8601", "http://en.wikipedia.org/wiki/ISO_8601"
          format.
        %p
          Use the following Ruby code:
          %code Date.today.to_s
%p The following fields are optional because not every planning authority provides them. Please do include them if data is available.

%table.scraper_fields
  %tbody
    %tr
      %th.field field
      %th.example Example value
      %th Description
    %tr
      %td.field date_received
      %td.example 2012-06-23
      %td
        %p
          The date this application was received by council. Should be in
          = link_to "ISO 8601", "http://en.wikipedia.org/wiki/ISO_8601"
          format.
    %tr
      %td.field on_notice_from
      %td.example 2012-08-01
      %td
        %p
          The date from when public submissions can be made about this application. Should be in
          = link_to "ISO 8601", "http://en.wikipedia.org/wiki/ISO_8601"
          format.
    %tr
      %td.field on_notice_to
      %td.example 2012-08-14
      %td
        %p
          The date until when public submissions can be made about this application. Should be in
          = link_to "ISO 8601", "http://en.wikipedia.org/wiki/ISO_8601"
          format.

%p
  To ensure the date_scraped field isn't overwritten on subsequent scrapes add code similar to this to
  save your planning application to the ScraperWiki datastore:

%code.long-lines
  %pre
    :preserve
      if (ScraperWiki.select("* from swdata where `council_reference`='\#{record['council_reference']}'").empty? rescue true)
        ScraperWiki.save_sqlite(['council_reference'], record)
      else
        puts "Skipping already saved record " + record['council_reference']
      end

%p
  If you get stuck, have a look at
  = link_to "the scrapers already written for PlanningAlerts", "https://scraperwiki.com/tags/planningalerts.org.au"
  and email
  = link_to "community mailing list", "http://groups.google.com/group/openaustralia-dev"
  if you have any questions.

%h4 Scheduling the scraper
%p
  Set the scraper to run once per day. This can be done on ScraperWiki on the main page of the scraper.

%h4 Finishing up
%p
  Once you've finished your scraper and it's successfully downloading planning applications, simply
  email the OpenAustralia Community mailing list or
  = mail_to "contact@planningalerts.org.au", "contact@planningalerts.org.au"
  and we'll add it to the next run.
%p
  The last thing to do is look up on Wikipedia how many people live within the council you've just covered so you can
  pat yourself on the back knowing that you've just helped tens of thousands of people get PlanningAlerts.
